from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain
import os

# Establecer la API key desde variable de entorno
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_KEY")

# 1. Crear memoria para la conversaciÃ³n
memory = ConversationBufferMemory(return_messages=True)

# 2. Crear el prompt con historial de mensajes
prompt = ChatPromptTemplate.from_messages([
    ("system", "Eres un asistente conversacional amigable y Ãºtil."),
    MessagesPlaceholder(variable_name="history"),
    ("human", "{input}")
])

# 3. Crear el modelo LLM
llm = ChatOpenAI(temperature=0.7, model="gpt-3.5-turbo")

# 4. Crear la cadena conversacional
conversation = ConversationChain(
    memory=memory,
    prompt=prompt,
    llm=llm,
    verbose=True
)

# 5. Ejecutar una conversaciÃ³n de ejemplo
conversation.invoke({"input": "Hola, Â¿puedes recordarme mi nombre si te lo digo?"})
conversation.invoke({"input": "Me llamo Enrique, recuÃ©rdalo."})
response = conversation.invoke({"input": "Â¿CuÃ¡l es mi nombre?"})

print("ðŸ§  Respuesta final:", response['response'])